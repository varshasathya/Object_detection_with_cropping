{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from abc import ABC,abstractmethod\n",
    "import json\n",
    "\n",
    "execution_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base class\n",
    "class ObjectType(ABC):\n",
    "    @abstractmethod\n",
    "    def toJSON(self):\n",
    "        pass\n",
    "    \n",
    "class ListType(ABC):\n",
    "    @abstractmethod\n",
    "    def toJSON(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object name, four pairs of coordinates and confidence score\n",
    "class DetectedObject(ObjectType):\n",
    "    def __init__(self,object_name,x0,y0,x1,y1,x2,y2,x3,y3,confidence_score):\n",
    "        self.object_name=object_name\n",
    "        self.x0=x0\n",
    "        self.y0=y0\n",
    "        self.x1=x1\n",
    "        self.y1=y1\n",
    "        self.x2=x2\n",
    "        self.y2=y2\n",
    "        self.x3=x3\n",
    "        self.y3=y3\n",
    "        self.confidence_score=confidence_score\n",
    "    def toJSON(self):\n",
    "        return json.dumps(self,default=lambda obj:obj.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectedObjectList(ListType):\n",
    "    def __init__(self,detected_objects):\n",
    "        self.detected_objects=detected_objects\n",
    "    def toJSON(self):\n",
    "        return json.dumps(self,default=lambda obj:obj.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the output layer names in the architecture\n",
    "def get_output_layers(net):\n",
    "    \n",
    "    layer_names = net.getLayerNames()\n",
    "    \n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to draw bounding box on the detected object with class name and also to crop detected object\n",
    "def draw_prediction(img, classes,class_id, confidence, x, y, x_plus_w, y_plus_h,COLORS):\n",
    "    confidence=round(confidence,4)\n",
    "    confidencesc=str(confidence)\n",
    "    label = str(classes[class_id]+'-'+confidencesc)\n",
    "    color = COLORS[class_id]\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    #Add these two lines to crop the detected object from the image\n",
    "    roi=img[y:y+y_plus_h,x:x+x_plus_w]\n",
    "    cv2.imwrite(str(label) + '.jpg', roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(image,config,weights):\n",
    "    # read input image    \n",
    "    image = cv2.imread(image)\n",
    "\n",
    "    Width = image.shape[1]\n",
    "    Height = image.shape[0]\n",
    "    scale = 0.00392\n",
    "\n",
    "    #pre-trained models that was trained on the COCO dataset which has 80 different kind of common everyday objects\n",
    "    classes=['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "    # generate different colors for different classes \n",
    "    COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "    # read pre-trained model and config file\n",
    "    net = cv2.dnn.readNet(weights, config)\n",
    "\n",
    "    #step to find image blobs ie.regions where a set of similar points get differentiated from one another\n",
    "    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "    # set input blob for the network\n",
    "    net.setInput(blob)\n",
    "\n",
    "    #run inference through the network and gather predictions from output layers\n",
    "    outs = net.forward(get_output_layers(net))\n",
    "\n",
    "    #initialization\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.5\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    # for each detetion from each output layer getting the confidence, class id, bounding box params and ignoring weak detections (confidence < 0.5)\n",
    "    for out in outs:\n",
    "\n",
    "        for detection in out:\n",
    "\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * Width)\n",
    "                center_y = int(detection[1] * Height)\n",
    "                w = int(detection[2] * Width)\n",
    "                h = int(detection[3] * Height)\n",
    "                x = center_x - w / 2\n",
    "                y = center_y - h / 2\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "#                 (x,y)--> top-left edge of the bounding box, w-->width h-->height\n",
    "                boxes.append([x, y, w, h])\n",
    "                \n",
    "                \n",
    "    objects=[]\n",
    "    \n",
    "    # apply non-max suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    # go through the detections remaining after nms and draw bounding box\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        x = box[0]\n",
    "        y = box[1]\n",
    "        w = box[2]\n",
    "        h = box[3]\n",
    "        #pass detected objects,four pairs of coordinates calculated from x,y,w,h and confidence score to the class \n",
    "        object_1=DetectedObject(classes[class_ids[i]],round(x), round(y), round(x+w), round(y+h),round(x), round(y), round(x+w), round(y+h),confidences[i])\n",
    "        objects.append(object_1)\n",
    "        #draw bounding box\n",
    "        draw_prediction(image,classes, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h),COLORS)\n",
    "    #create json file with the acquired results. \n",
    "    object_list=DetectedObjectList(objects)\n",
    "    object_json=object_list.toJSON()\n",
    "    # save output image \n",
    "    cv2.imwrite(os.path.join(execution_path ,\"sample_output/output_image.jpg\"), image)\n",
    "    return object_json\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=os.path.join(execution_path , \"sample_input/input2.jpg\")#image path\n",
    "\n",
    "config=os.path.join(execution_path , \"yolov3.cfg\")#config path of the network\n",
    "\n",
    "#Kindly download the weight files from https://pjreddie.com/media/files/yolov3.weights\n",
     "\n",
    "weights=os.path.join(execution_path , \"yolov3.weights\")#pre-trained YOLO v3 weights\n",
    "\n",
    "object_json=object_detection(image,config,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"detected_objects\": [{\"object_name\": \"person\", \"x0\": 190, \"y0\": 94, \"x1\": 276, \"y1\": 378, \"x2\": 190, \"y2\": 94, \"x3\": 276, \"y3\": 378, \"confidence_score\": 0.9999475479125977}, {\"object_name\": \"horse\", \"x0\": 394, \"y0\": 137, \"x1\": 608, \"y1\": 343, \"x2\": 394, \"y2\": 137, \"x3\": 608, \"y3\": 343, \"confidence_score\": 0.9977301955223083}, {\"object_name\": \"dog\", \"x0\": 59, \"y0\": 262, \"x1\": 205, \"y1\": 350, \"x2\": 59, \"y2\": 262, \"x3\": 205, \"y3\": 350, \"confidence_score\": 0.9942072629928589}]}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
